{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.3.56-cp37-cp37m-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in f:\\machine_learning\\online-study\\computer-vision\\person_detection_work\\venv\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.3.56\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.7.0-cp37-cp37m-win_amd64.whl (33.6 MB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in f:\\machine_learning\\online-study\\computer-vision\\person_detection_work\\venv\\lib\\site-packages (from scipy) (1.19.5)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "Import the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-IMl4b6BdGO"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import linecache\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF-YlMl8c_bM"
   },
   "outputs": [],
   "source": [
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoader:\n",
    "    def load_model(self, model_name):\n",
    "        #If we want to download a new model\n",
    "        #base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "        model_file = model_name + '.tar.gz'\n",
    "        #model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file,untar=True)\n",
    "        model_dir = \"saved_models\"/pathlib.Path(model_name)/\"saved_model\"\n",
    "\n",
    "        model = tf.saved_model.load(str(model_dir))\n",
    "        model = model.signatures['serving_default']\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "\n",
    "PATH_TO_LABELS = 'F:/Machine_learning/Online-study/computer-vision/person_detection_work/models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7aOtOlebK7h"
   },
   "source": [
    "#### Loading the saved object detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XNT0wxybKR6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "detection_model = ModelLoader().load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JP5qZ7sXJpwG"
   },
   "source": [
    "Add a wrapper function to call the model, and cleanup the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajmR_exWyN76"
   },
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    def run_inference_for_single_image(self, model, image):\n",
    "        image = np.asarray(image)\n",
    "        # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "        input_tensor = tf.convert_to_tensor(image)\n",
    "        # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "        input_tensor = input_tensor[tf.newaxis,...]\n",
    "        # Run inference\n",
    "        output_dict = model(input_tensor)\n",
    "        num_detections = int(output_dict.pop('num_detections'))\n",
    "        output_dict = {key:value[0, :num_detections].numpy() \n",
    "                     for key,value in output_dict.items()}\n",
    "        output_dict['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "        # Handle models with masks:\n",
    "\n",
    "        if 'detection_masks' in output_dict:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                      output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "                       image.shape[0], image.shape[1])\n",
    "            detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                               tf.uint8)\n",
    "            output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "        return output_dict\n",
    "    \n",
    "    def show_inference(self, model, image_path):\n",
    "        # the array based representation of the image will be used later in order to prepare the\n",
    "        # result image with boxes and labels on it.\n",
    "        image_np = image_path\n",
    "        # Actual detection.\n",
    "        output_dict = self.run_inference_for_single_image(model, image_np)\n",
    "        # Visualization of the results of a detection.\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          output_dict['detection_boxes'],\n",
    "          output_dict['detection_classes'],\n",
    "          output_dict['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "\n",
    "        return image_np, output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1wq0LVyMRR_"
   },
   "source": [
    "Run it on each test image and show the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWh_1zz6aqxs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetClassAndBoundingBox:\n",
    "    def get_boxes(self, op_dict):\n",
    "        boxes = []\n",
    "        classes = []\n",
    "        for i in range(op_dict[\"num_detections\"]):\n",
    "            if op_dict[\"detection_scores\"][i] > 0.5:\n",
    "                boxes.append(op_dict[\"detection_boxes\"][i])\n",
    "                classes.append(op_dict[\"detection_classes\"][i])\n",
    "        return boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"G:/video_detect_khushi/videos/football_min1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1, 1, 1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [37, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [37, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  []\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [37, 1, 1, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [37, 1, 1, 1, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [37, 1, 1, 1, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [37, 1, 1, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [37, 1, 1, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [37, 1, 1, 1]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [19, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [19, 1]\n",
      "False\n",
      "CLASS :  [19]\n",
      "False\n",
      "CLASS :  [19]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [19, 1]\n",
      "False\n",
      "CLASS :  [19, 1]\n",
      "False\n",
      "CLASS :  [19]\n",
      "False\n",
      "CLASS :  [19]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 37]\n",
      "True\n",
      "BALLLL -----  1\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1, 1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n",
      "CLASS :  [1]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "person=0\n",
    "ball=0\n",
    "othors=0\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(vid)\n",
    "\n",
    "# For calculatig seek time\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)      \n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(frame_count)\n",
    "duration = frame_count/fps\n",
    "\n",
    "out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (600,600))\n",
    "\n",
    "font = ImageFont.truetype('arial.ttf', 30)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    #success is boolean and image contains frame of the video\n",
    "    try:\n",
    "        success, vimg = cap.read()\n",
    "        if success:\n",
    "            img, op_dict = ObjectDetection().show_inference(detection_model, vimg)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            \n",
    "            #print(\"------------\",frame_count,\"--------------\")\n",
    "            seek_time = cap.get(cv2.CAP_PROP_POS_MSEC)/1000\n",
    "            seek_time = round(seek_time, 2)\n",
    "            \n",
    "            # Fetching the bounding box coordinates\n",
    "            boxes, classes = GetClassAndBoundingBox().get_boxes(op_dict)\n",
    "            print(\"CLASS : \",classes)\n",
    "            print(37 in classes)\n",
    "            if len(classes) and (1 in classes):\n",
    "                person += classes.count(1)\n",
    "            if len(classes) and (37 in classes):\n",
    "                print(\"BALLLL ----- \",classes.count(37))\n",
    "                ball += classes.count(37)\n",
    "            \n",
    "            vimg = cv2.resize(img, (1200,690))\n",
    "            vimg = cv2.putText(vimg,\"Time : \" + str(seek_time), (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            if frame_count == frame_count - 1:\n",
    "                vimg = cv2.putText(vimg,\"Inferences written in csv file.\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Frame\",vimg)\n",
    "            #time.sleep(1)\n",
    "            result.write(vimg)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        f = tb.tb_frame\n",
    "        lineno = tb.tb_lineno\n",
    "        print('EXCEPTION IN LINE ', lineno , \" exception : \" , exc_obj)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times person was detected in the video:  433\n",
      "Number of times ball was detected in the video  :  15\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of times person was detected in the video: \", person)\n",
    "print(\"Number of times ball was detected in the video  : \", ball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ball_position': 'possessed', 'from': 0.92, 'to': 1.4},\n",
       " {'ball_position': 'in_air', 'from': 1.4, 'to': 3.96},\n",
       " {'ball_position': 'possessed', 'from': 3.96, 'to': 4.36},\n",
       " {'ball_position': 'in_air', 'from': 4.36, 'to': 4.72},\n",
       " {'ball_position': 'possessed', 'from': 4.72, 'to': 4.76}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball_possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"rugby.png\")\n",
    "img, op_dict = show_inference(detection_model, img)\n",
    "boxes = []\n",
    "min_threshold = 0.55\n",
    "for i in range(op_dict[\"num_detections\"]):\n",
    "    if op_dict[\"detection_scores\"][i] > min_threshold:\n",
    "        boxes.append(op_dict[\"detection_boxes\"][i])\n",
    "\n",
    "image_pil = Image.fromarray(np.uint8(img)).convert('RGB')\n",
    "im_width, im_height = image_pil.size\n",
    "\n",
    "for box in boxes:\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "    \n",
    "    height = bottom - top\n",
    "    width = right - left\n",
    "    half_height = height/2\n",
    "    half_width = width/2\n",
    "    centroid_of_x_axis = top+half_height \n",
    "    centroid_of_y_axis = left+half_width\n",
    "\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    draw.rectangle([(left, top), (right, bottom)], width=1)\n",
    "    draw.ellipse((centroid_of_y_axis, centroid_of_x_axis, centroid_of_y_axis+10, centroid_of_x_axis+10), fill = 'yellow')\n",
    "    \n",
    "    np.copyto(img, np.array(image_pil))\n",
    "\n",
    "image_pil.show()\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
